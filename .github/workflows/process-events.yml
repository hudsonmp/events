name: Process New Instagram Posts for Events

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of posts to process (default: all unprocessed)'
        required: false
        default: ''
  workflow_run:
    workflows: ["Instagram Scraper (Hourly)"]
    types:
      - completed
  repository_dispatch:
    types: [process-events]

jobs:
  extract-events:
    runs-on: ubuntu-latest
    # Only run if the scraper workflow completed successfully, or if manually triggered
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' || github.event_name == 'repository_dispatch' }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run AI Event Extraction
      env:
        SUPABASE_PROJECT_URL: ${{ secrets.SUPABASE_PROJECT_URL }}
        SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}
        GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
      run: |
        cd instagram/extraction
        if [ -n "${{ github.event.inputs.batch_size }}" ]; then
          python ai.py ${{ github.event.inputs.batch_size }}
        elif [ -n "${{ github.event.client_payload.batch_size }}" ]; then
          python ai.py ${{ github.event.client_payload.batch_size }}
        else
          python ai.py
        fi
    
    - name: Upload extraction logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: extraction-logs-${{ github.run_number }}
        path: |
          instagram/extraction/*.log
        retention-days: 7 